
This directory contains code and Excel files that simulate various scenarios in
the SDR papers [1, 2] and the Neuron paper [3]. They are used to generate the numerical
results. The code also serves to verify the formulas in the papers.

The papers are available here:

[1] Ahmad, S., and Hawkins, J. (2015). *Properties of Sparse Distributed
Representations and their Application to Hierarchical Temporal Memory*.
*arXiv:1503.07469** Neurons and Cognition; Artificial Intelligence. Retrieved
from http://arxiv.org/abs/1503.07469

[2] Ahmad, S., and Hawkins, J. (2016). *How do neurons operate on sparse
distributed representations? A mathematical theory of sparsity, neurons and
active dendrites*. **arXiv:1601.00720** Neurons and Cognition; Artificial
Intelligence. Retrieved from http://arxiv.org/abs/1601.00720

[3] Hawkins, J., and Ahmad, S. (2016). Why Neurons Have Thousands of Synapses, a
Theory of Sequence Memory in Neocortex. Front. Neural Circuits 10.
doi:10.3389/fncir.2016.00023. PDF:
http://journal.frontiersin.org/article/10.3389/fncir.2016.00023/full


SDR Properties Calculations.xlsx
================================

This excel file contains the formulas in the SDR papers. You can plug in 
different numbers and it tells you the result of various formulas.  Excel  uses
very high precision math, so you can compute the numbers for any  reasonable set
of parameters. (A much wider range than you can by simulations.) This
spreadsheet was used to compute the numbers in the examples and the tables in
the SDR paper.


sdr_math_neuron_paper.ipynb
===========================

An ipython notebook showing how to implement and compute the functions in
python using a symbolic math library.  This notebook also contains some of the
loops used to generate the numbers in the plots.


Optimal threshold
=================

compute_optimal_threshold.py computes averaged errors over a wide range of
values. The file plot_optimal_threshold.py plots the curve as a function of
theta and outlines the "optimal" area.


sdr_calculations[12].cpp
=====================

These C++ programs simulate SDR classification with various parameters.  In
particular it simulates the "Classifying a Set of Vectors" setup. You can set
values for M, n, and w and it will return the probability of a false match
for various values of theta. It computes these probabilities via simulations
(i.e. generating millions of random vectors and using a classifier to compute
whether there was a match or not).  It can also test false negatives with noise.

As such this can be used to verify that the math in the paper is accurate.

However, we can only really verify the math for relatively small parameters
this way. Many of the probabilities are insanely low and it is impossible to
verify via simulation.  Still if the math matches the simulation results
exactly for a wide range of parameters, we can be reasonably sure it is
accurate.

Currently you need to hard code the numbers in the C++ file,  compile and run.
Sorry about that. Here is an example run on my laptop:

For n=100, M=500, w=7 and setting nTrials to 1,000,000 it takes 10 minutes to
generate the following result:
```
Classification: Probability of false match for n=100, M=500, w=7
    Theta = 1 prob=1
    Theta = 2 prob=1
    Theta = 3 prob=0.964839
    Theta = 4 prob=0.134632
    Theta = 5 prob=0.00285
    Theta = 6 prob=1.7e-05
    Theta = 7 prob=0
```

These correspond quite closely to the formula in the paper. For example, for
theta=5 the formula leads to 0.002826477. For theta=4 the formula leads to
0.144691001.  For theta=6 the formula leads to 2.03654E-05

Remember  that  the formula is an upper bound on the classification error. It
will be less accurate as you get closer to 1.0. The simulations themselves will
be less accurate for really tiny numbers since we are running a finite number of
trials.  As an example, For theta=7 the  formula leads to 3.12352E-08 but we
need to run hundreds of millions of  trials to get that number through
simulations.

Plots
=====

There are various plotting scripts that generate images using plot.ly. Each
script contains the numbers calculated using one of the above methods. The image
below shows an example plot generated by plot_effect_of_n.py.

This graph illustrates the behavior of the main equation and the effects of cell
population and sparsity. The three solid curves show the rapid drop in error
rates as the number of cells n increases. Each curve shows a different sparsity
level. For example, if 128 out of 4000 cells are active (3.2% sparsity) the
error rate is a little higher than 10-12. The dashed line corresponds to an
activity level of 50%. The fact that the error corresponding to this condition
does not drop demonstrates that both sparsity and high dimensionality are
required to achieve low error rates. In all of these simulations, the number of
synapses s=24 and the dendritic threshold theta=12, corresponding to 50% noise
tolerance.

![Effect of n](https://github.com/numenta/nupic.research/blob/31f45e19903bacff308b36e07609d25059c63de0/projects/sdr_paper/images/effect_of_n.png)


Note on using NuPIC Core
========================

The executable `sdr_calculations` is a C++ program that is a client of 
`nupic.core`. As such it is an example of how to write C++ programs that use
that repository as an external library. I have tried to make it as simple as
possible. 

There is a single, very simplistic, Makefile that shows how to compile and link
such code.  The Makefile assumes the environment variable `NUPIC_CORE` is
already setup to point to the root of your `nupic.core` repository.  It 
assumes you have followed the `nupic.core` build instructions and have a 
proper build in place. 

